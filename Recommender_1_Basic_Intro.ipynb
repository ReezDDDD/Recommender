{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommender_1_Basic_Intro",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur8eNnM9uA0Y"
      },
      "source": [
        "# What is a recommendation model?\n",
        "An ML-based recommendation model determines how similar items are to other things you like and then serves up a recommendation.\n",
        "\n",
        "There two major types:\n",
        "  - User-based\n",
        "  - Item-based"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hay5XwApuKKQ"
      },
      "source": [
        "# Why recommendations?\n",
        "A recommendation system helps users find compelling content in a large corpora. \n",
        "For example, the Google Play Store provides millions of apps, while YouTube provides billions of videos. More apps and videos are added every day. How can users find new compelling content? Yes, one can use search to access content. However, a recommendation engine can display items that users might not have thought to search for on their own."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_NHqH7tuQra"
      },
      "source": [
        "# Terminology\n",
        "- Item\n",
        "\n",
        " The entities a system recommends. \n",
        "\n",
        "- Query\n",
        "\n",
        " The information a system uses to make recommendations. \n",
        "\n",
        "- Embedding\n",
        "\n",
        " A mapping from a discrete set (in this case, the set of queries, or the set of items to recommend) to a vector space called the embedding space. Many recommendation systems rely on learning an appropriate embedding representation of the queries and items.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7SncV5opkww"
      },
      "source": [
        "# Recommendation System Over - An IR Point of View\n",
        "### Candidate Generation -> Scoring -> Re-ranking\n",
        "- Candidate Generation\n",
        "\n",
        " In this first stage, the system starts from a potentially huge corpus and generates a much smaller subset of candidates. For example, the candidate generator in YouTube reduces billions of videos down to hundreds or thousands. The model needs to evaluate queries quickly given the enormous size of the corpus. A given model may provide multiple candidate generators, each nominating a different subset of candidates. **In this stage, we can use metrics which are not very precise/strict, for example, mAP@1000.**\n",
        "\n",
        "- Scoring\n",
        "\n",
        " Next, another model scores and ranks the candidates in order to select the set of items to display to the user. Since this model evaluates a relatively small subset of items, the system can use a more precise model relying on additional queries. **Also, more strict/precise metrics.**\n",
        "\n",
        "- Re-ranking\n",
        "\n",
        " Finally, the system must take into account additional constraints**(business rules)** for the final ranking. For example, the system removes items that the user explicitly disliked or boosts the score of fresher content. Re-ranking can also help ensure diversity, freshness, and fairness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0RkBxjoLATS"
      },
      "source": [
        "# Candidate Generation\n",
        "\n",
        "### Classic Approaches\n",
        "\n",
        "- Content-based Filtering\n",
        " \n",
        " Uses similarity between items to recommend items similar to what the user likes. **If user A watches two cute cat videos, then the system can recommend cute animal videos to that user.**\n",
        "\n",
        "\n",
        "- Collaborative Filtering\n",
        "\n",
        " Uses similarities between queries and items simultaneously to provide recommendations. **If user A is similar to user B, and user B likes video 1, then the system can recommend video 1 to user A (even if user A hasn’t seen any videos similar to video 1).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5HozpZ6ODd0"
      },
      "source": [
        "### Embedding Space and Similarity Measurments\n",
        "\n",
        "- Embedding Space\n",
        "  \n",
        "  Both content-based and collaborative filtering **map each item and each query (or context) to an embedding vector in a common embedding space.** Typically, the embedding space is **low-dimensional (much smaller than the size of the corpus)**, and captures some latent structure of the item or query set. Similar items, such as YouTube videos that are usually watched by the same user, end up close together in the embedding space.\n",
        "\n",
        "- Similarity Measurements\n",
        "\n",
        " **A similarity measure is a function that takes a pair of embeddings and returns a scalar measuring their similarity.** The embeddings can be used for candidate generation as follows: given a query embedding _q_, the system looks for item embeddings that are close to _q_, that is, embeddings with high similarity.\n",
        "\n",
        "  - Cosine\n",
        "  \n",
        "   Describe the **\"angle\"** between two vectors/embeddings\n",
        "\n",
        "  - Dot Product\n",
        "  \n",
        "   The dot product between two vectors/embeddings. Recall the formula of cosine similarity, **if these two vectors have already been normalized, then the dot product and cosine similarity coincide.**\n",
        "\n",
        "  - Euclidean Distance\n",
        "  \n",
        "   A smaller distance means higher similarity. **Note that when the embeddings are normalized, the squared Euclidean distance coincides with dot-product (and cosine) up to a constant.**\n",
        "\n",
        " - Which Similarity Measure to Choose?\n",
        "  \n",
        "   Compared to the cosine, **the dot product similarity is sensitive to the norm of the embedding.** That is, the larger the norm of an embedding, the higher the similarity (for items with an acute angle) and the more likely the item is to be recommended. This can affect recommendations as follows:\n",
        "\n",
        "   - **Items that appear very frequently in the training set tend to have embeddings with large norms.** If capturing popularity information is desirable, then you should prefer dot product. However, if you're not careful, the popular items may end up dominating the recommendations. In practice, you can use other variants of similarity measures that put less emphasis on the norm of the item.\n",
        "\n",
        "   - **Items that appear very rarely may not be updated frequently during training.** Consequently, if they are initialized with a large norm, the system may recommend rare items over more relevant items. To avoid this problem, be careful about embedding initialization, and use appropriate regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHhrMo4Yf85v"
      },
      "source": [
        "# Content-based Filtering\n",
        "\n",
        "- Advantages\n",
        "\n",
        " - **The model doesn't need any data about other users, since the recommendations are specific to this user.** This makes it easier to scale to a large number of users.\n",
        "\n",
        " - **The model can capture the specific interests of a user,** and can recommend niche items that very few other users are interested in.\n",
        "\n",
        "- Disadvantages\n",
        "\n",
        " - Since the feature representation of the items are hand-engineered to some extent, this technique requires a lot of domain knowledge. Therefore, the model can only be as good as the hand-engineered features.\n",
        "\n",
        " - **The model can only make recommendations based on existing interests of the user.** In other words, the model has limited ability to expand on the users' existing interests.\n",
        "\n",
        "\n",
        "Use ml-25m dataset for demonstrating. For simplicity, we will only use genres of the movie to build the embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEfEinFO_jN_"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASRtahx1NAH4",
        "outputId": "bbcd6783-324a-441e-cae7-6f1b1010d861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "movie = pd.read_csv(\"/content/drive/My Drive/Data/Movielens/ml-25m/movies.csv\")\n",
        "movie.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62423, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU6hxVCWNAKd",
        "outputId": "61456c34-0eeb-4c1b-d401-4d0ab992bc88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "movie.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieId  ...                                       genres\n",
              "0        1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
              "1        2  ...                   Adventure|Children|Fantasy\n",
              "2        3  ...                               Comedy|Romance\n",
              "3        4  ...                         Comedy|Drama|Romance\n",
              "4        5  ...                                       Comedy\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diZLuqAAVaLy"
      },
      "source": [
        "class ContentFiltering():\n",
        "  \n",
        "  def __init__(self, movie, limit=-1):\n",
        "    self.movie = movie\n",
        "    if limit != -1:\n",
        "      self.corpus = self.movie[\"genres\"][:limit]\n",
        "    else:\n",
        "      self.corpus = self.movie[\"genres\"]\n",
        "    self.embeddings = None\n",
        "    self.predictions = None\n",
        "    self.vectorizer = None\n",
        "\n",
        "  def train(self):\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "    # Use tfidf to represent the embedding matrix, note by default it applys l2 norm\n",
        "    self.vectorizer = TfidfVectorizer()\n",
        "    self.embeddings = self.vectorizer.fit_transform(self.corpus)\n",
        "\n",
        "    # Thus we can use either cosine or dot product as our measurement metric\n",
        "    self.predictions = cosine_similarity(self.embeddings, self.embeddings)\n",
        "\n",
        "  def get_feature_name(self):\n",
        "    return self.vectorizer.get_feature_names()\n",
        "\n",
        "  def get_embedding_matrix(self):\n",
        "    return self.embeddings.todense()\n",
        "\n",
        "  def predict(self, movieId, topk=10):\n",
        "    result = []\n",
        "    index = self.movie.index[self.movie[\"movieId\"] == movieId]\n",
        "    indexs = self.predictions[index][0].argsort()[-2:-(topk+2):-1]\n",
        "    for i in indexs:\n",
        "      print(self.movie.iloc[i, 1:].values)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNTak0p9du3B"
      },
      "source": [
        "cb = ContentFiltering(movie, 20000)\n",
        "cb.train()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPX_q1yhqqhd",
        "outputId": "55f9e7d0-5d4d-4159-ff36-cf154da4dbaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "cb.get_feature_name()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['action',\n",
              " 'adventure',\n",
              " 'animation',\n",
              " 'children',\n",
              " 'comedy',\n",
              " 'crime',\n",
              " 'documentary',\n",
              " 'drama',\n",
              " 'fantasy',\n",
              " 'fi',\n",
              " 'film',\n",
              " 'genres',\n",
              " 'horror',\n",
              " 'imax',\n",
              " 'listed',\n",
              " 'musical',\n",
              " 'mystery',\n",
              " 'no',\n",
              " 'noir',\n",
              " 'romance',\n",
              " 'sci',\n",
              " 'thriller',\n",
              " 'war',\n",
              " 'western']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDGX23S9qs8Z",
        "outputId": "12e5dbc3-793b-414a-cb92-327c732d0d48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "cb.get_embedding_matrix()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.        , 0.40769171, 0.54285348, ..., 0.        , 0.        ,\n",
              "         0.        ],\n",
              "        [0.        , 0.50911033, 0.        , ..., 0.        , 0.        ,\n",
              "         0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "         0.        ],\n",
              "        ...,\n",
              "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "         0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "         0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "         0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVP8bRekqZUs",
        "outputId": "1f5e5f07-f421-459a-a64b-aa43dde1586c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "cb.predict(1, 20)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Antz (1998)' 'Adventure|Animation|Children|Comedy|Fantasy']\n",
            "[\"Emperor's New Groove, The (2000)\"\n",
            " 'Adventure|Animation|Children|Comedy|Fantasy']\n",
            "['Adventures of Rocky and Bullwinkle, The (2000)'\n",
            " 'Adventure|Animation|Children|Comedy|Fantasy']\n",
            "['DuckTales: The Movie - Treasure of the Lost Lamp (1990)'\n",
            " 'Adventure|Animation|Children|Comedy|Fantasy']\n",
            "['Toy Story 2 (1999)' 'Adventure|Animation|Children|Comedy|Fantasy']\n",
            "['Wild, The (2006)' 'Adventure|Animation|Children|Comedy|Fantasy']\n",
            "['Shrek the Third (2007)' 'Adventure|Animation|Children|Comedy|Fantasy']\n",
            "['Asterix and the Vikings (Astérix et les Vikings) (2006)'\n",
            " 'Adventure|Animation|Children|Comedy|Fantasy']\n",
            "['Tale of Despereaux, The (2008)'\n",
            " 'Adventure|Animation|Children|Comedy|Fantasy']\n",
            "['Monsters, Inc. (2001)' 'Adventure|Animation|Children|Comedy|Fantasy']\n",
            "['Valhalla (1986)' 'Adventure|Animation|Children|Fantasy']\n",
            "['Lord of the Rings, The (1978)' 'Adventure|Animation|Children|Fantasy']\n",
            "['Sinbad: Legend of the Seven Seas (2003)'\n",
            " 'Adventure|Animation|Children|Fantasy']\n",
            "['Black Cauldron, The (1985)' 'Adventure|Animation|Children|Fantasy']\n",
            "['Ponyo (Gake no ue no Ponyo) (2008)'\n",
            " 'Adventure|Animation|Children|Fantasy']\n",
            "[\"We're Back! A Dinosaur's Story (1993)\"\n",
            " 'Adventure|Animation|Children|Fantasy']\n",
            "['Cat Returns, The (Neko no ongaeshi) (2002)'\n",
            " 'Adventure|Animation|Children|Fantasy']\n",
            "['Kirikou and the Sorceress (Kirikou et la sorcière) (1998)'\n",
            " 'Adventure|Animation|Children|Fantasy']\n",
            "['Resan Till Melonia (1989)' 'Adventure|Animation|Children|Fantasy']\n",
            "['Phantom Tollbooth, The (1970)' 'Adventure|Animation|Children|Fantasy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-W4B5mAtDra"
      },
      "source": [
        "# Reference \n",
        "1. Google Recommendation Systems https://developers.google.com/machine-learning/recommendation\n",
        "2. Movielens https://grouplens.org/datasets/movielens/\n",
        "3. TfidfVectorizer https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "4. Cosine Similarity https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIRQuTae7nCa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}